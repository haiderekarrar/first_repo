The paper relies on various references, all of which are publicly available. The paper compares against protein structures in the past that have been deposited in the Protein Data Bank, which is a library filled with such completed structures. This is to verify the accuracy of the protein structures predicted using AlphaFold. UniRef90, Uniclust30, BFD, and MGnify are databases with sequences of proteins. These libraries are used to predict the structures of proteins by comparing the sequence of the protein with the sequences of its cousin proteins. The paper shows that removing BFD or MGnify measurably reduces accuracy, proving these sources are critical. The paper also references CASP, which is a blind community test in which teams submit the 3D structures of solved proteins that the organizers know the actual 3D structures of but have not released to the public. This is important because it is a blind test, and AlphaFold2’s showed significantly greater accuracy than other systems. The goal is defined by Anfinsen’s idea that a protein’s sequence determines its 3D shape, as well as Dill’s review on why predicting that shape is hard because very subtle factors change what the shape would look like. The paper of course also references the prior AlphaFold because that is what the new AlphaFold model is built on. The paper also relies on deep-learning “contact prediction” papers (2017–2019). These papers are about showing neural nets can spot which parts of a protein touch, which is important key groundwork for structure prediction. Finally, the study relies on standard accuracy scores (lDDT, GDT, and TM-score) so everyone can compare results on the same scale. 
